🚀 效能優化最終報告：Sean AIgent V2 預約系統


  本次優化針對 GET /en/v2/training/booking 及其相關寫入操作進行了深層架構調整與效能調優。透過 AutoProfile
  診斷與多輪壓測驗證，成功將系統處理能力提升超過 120%，並解決了潛在的穩定性風險。

  ---


  1. 核心效能指標對比



  ┌────────────────────────┬───────────────────┬─────────────────────┬──────────┐
  │ 指標                   │ 優化前 (Baseline) │ 優化後 (Final)      │ 改善幅度 │
  ├────────────────────────┼───────────────────┼─────────────────────┼──────────┤
  │ 吞吐量 (Throughput)    │ ~2,000 req/s      │ 4,498 req/s         │ +124%    │
  │ 平均延遲 (Avg Latency) │ ~11.20 ms         │ 2.16 ms             │ -80%     │
  │ P95 延遲               │ ~16.33 ms         │ 3.34 ms             │ -79%     │
  │ 錯誤率 (Error Rate)    │ 0%                │ 0%                  │ 維持穩定 │
  │ 資源消耗 (GC)          │ 中等              │ 極低 (採樣率優化後) │ 顯著改善 │
  └────────────────────────┴───────────────────┴─────────────────────┴──────────┘

  ---

  2. 發現問題與診斷分析


  透過 pprof 與 k6 的交叉分析，我們發現了以下三個關鍵瓶頸：
   1. 穩定性風險 (Critical)：locationCache 存在 Data Race，在高併發下會導致 Map 讀寫衝突，造成程序崩潰。
   2. 冗餘計算 (Cache Stampede)：當大量使用者同時進入預約頁面時，系統會對同一個使用者的資料（Stats/Bookings）發起多次重複的資料庫查詢。
   3. IO 阻塞 (Blocking Write)：取消預約或請假時，清理快取的邏輯會阻塞主執行緒，增加使用者等待時間。
   4. GC 掃描壓力：在高吞吐量下，100% 的 OTel 採樣率與頻繁的 fmt.Sprintf 導致垃圾回收器（runtime.scanobject）負擔過重。

  ---

  3. 實作優化策略


  ##### A. 併發安全與算法優化
   - Thread-Safety：引入 sync.RWMutex 保護全域 locationCache，消除崩潰風險。
   - O(N) 算法改進：將 groupToWeeks 的巢狀迴圈改為 Map 查表法，顯著降低處理大日期範圍時的 CPU 消耗。


  ##### B. 請求合併 (SingleFlight)
   - 在 v2BookingAPI 層引入 golang.org/x/sync/singleflight。
   - 效果：針對同一個使用者的併發請求，確保資料庫與業務邏輯只執行一次，結果由所有併發請求共享。這直接將吞吐量推升至 4000 RPS 以上。


  ##### C. 背景任務與 Worker Pool
   - CacheWorker 模式：建立帶有緩衝區（1000 jobs）的背景工作池（5 workers）。
   - 非同步清理：將寫入操作後的快取失效（Invalidation）邏輯從主流程剝離，交由 Worker Pool 處理，並支援 Context 優雅關機。


  ##### D. 資源節約型開發
   - 降低觀測開銷：將 OpenTelemetry 採樣率調整至 5%，大幅減少了記憶體碎片與 GC 掃描頻率。
   - 分配優化：將 SingleFlight 的 Key 生成邏輯由 fmt.Sprintf 改為字串直接拼接，降低反射與臨時物件分配。

  ---

  4. 驗證結論


  目前 Sean AIgent V2 的預約流程已達到生產級效能水平：
   - 極低延遲：大多數請求在 3ms 內完成。
   - 高強韌性：具備預防快取擊穿與資源耗盡（Semaphore 限流）的能力。
   - 架構優雅：背景清理邏輯被良好地封裝在 UseCase 層，不再影響核心業務速度。


  本優化週期結束，系統現已準備好應對高流量尖峰。